// This file was auto-generated by Fern from our API Definition.

import { mockServerPool } from "../../mock-server/MockServerPool";
import { ElevenLabsClient } from "../../../src/Client";

describe("BatchCalls", () => {
    test("create", async () => {
        const server = mockServerPool.createServer();
        const client = new ElevenLabsClient({ apiKey: "test", environment: server.baseUrl });
        const rawRequestBody = {
            call_name: "call_name",
            agent_id: "agent_id",
            agent_phone_number_id: "agent_phone_number_id",
            recipients: [{ phone_number: "phone_number" }],
        };
        const rawResponseBody = {
            id: "id",
            phone_number_id: "phone_number_id",
            phone_provider: "twilio",
            name: "name",
            agent_id: "agent_id",
            created_at_unix: 1,
            scheduled_time_unix: 1,
            total_calls_dispatched: 1,
            total_calls_scheduled: 1,
            last_updated_at_unix: 1,
            status: "pending",
            agent_name: "agent_name",
        };
        server
            .mockEndpoint()
            .post("/v1/convai/batch-calling/submit")
            .jsonBody(rawRequestBody)
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.conversationalAi.batchCalls.create({
            callName: "call_name",
            agentId: "agent_id",
            agentPhoneNumberId: "agent_phone_number_id",
            recipients: [
                {
                    phoneNumber: "phone_number",
                },
            ],
        });
        expect(response).toEqual({
            id: "id",
            phoneNumberId: "phone_number_id",
            phoneProvider: "twilio",
            name: "name",
            agentId: "agent_id",
            createdAtUnix: 1,
            scheduledTimeUnix: 1,
            totalCallsDispatched: 1,
            totalCallsScheduled: 1,
            lastUpdatedAtUnix: 1,
            status: "pending",
            agentName: "agent_name",
        });
    });

    test("list", async () => {
        const server = mockServerPool.createServer();
        const client = new ElevenLabsClient({ apiKey: "test", environment: server.baseUrl });

        const rawResponseBody = {
            batch_calls: [
                {
                    id: "id",
                    phone_number_id: "phone_number_id",
                    phone_provider: "twilio",
                    name: "name",
                    agent_id: "agent_id",
                    created_at_unix: 1,
                    scheduled_time_unix: 1,
                    total_calls_dispatched: 1,
                    total_calls_scheduled: 1,
                    last_updated_at_unix: 1,
                    status: "pending",
                    agent_name: "agent_name",
                },
            ],
            next_doc: "next_doc",
            has_more: true,
        };
        server
            .mockEndpoint()
            .get("/v1/convai/batch-calling/workspace")
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.conversationalAi.batchCalls.list({
            limit: 1,
            lastDoc: "last_doc",
        });
        expect(response).toEqual({
            batchCalls: [
                {
                    id: "id",
                    phoneNumberId: "phone_number_id",
                    phoneProvider: "twilio",
                    name: "name",
                    agentId: "agent_id",
                    createdAtUnix: 1,
                    scheduledTimeUnix: 1,
                    totalCallsDispatched: 1,
                    totalCallsScheduled: 1,
                    lastUpdatedAtUnix: 1,
                    status: "pending",
                    agentName: "agent_name",
                },
            ],
            nextDoc: "next_doc",
            hasMore: true,
        });
    });

    test("get", async () => {
        const server = mockServerPool.createServer();
        const client = new ElevenLabsClient({ apiKey: "test", environment: server.baseUrl });

        const rawResponseBody = {
            id: "id",
            phone_number_id: "phone_number_id",
            phone_provider: "twilio",
            name: "name",
            agent_id: "agent_id",
            created_at_unix: 1,
            scheduled_time_unix: 1,
            total_calls_dispatched: 1,
            total_calls_scheduled: 1,
            last_updated_at_unix: 1,
            status: "pending",
            agent_name: "agent_name",
            recipients: [
                {
                    id: "id",
                    phone_number: "phone_number",
                    status: "pending",
                    created_at_unix: 1,
                    updated_at_unix: 1,
                    conversation_id: "conversation_id",
                    conversation_initiation_client_data: {
                        conversation_config_override: {
                            tts: { voice_id: "cjVigY5qzO86Huf0OWal", stability: 0.5, speed: 1, similarity_boost: 0.8 },
                            conversation: undefined,
                            agent: {
                                first_message: "Hello, how can I help you today?",
                                language: "en",
                                prompt: {
                                    prompt: "You are a helpful assistant that can answer questions about the topic of the conversation.",
                                    native_mcp_server_ids: undefined,
                                },
                            },
                        },
                        user_id: undefined,
                    },
                },
            ],
        };
        server
            .mockEndpoint()
            .get("/v1/convai/batch-calling/batch_id")
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.conversationalAi.batchCalls.get("batch_id");
        expect(response).toEqual({
            id: "id",
            phoneNumberId: "phone_number_id",
            phoneProvider: "twilio",
            name: "name",
            agentId: "agent_id",
            createdAtUnix: 1,
            scheduledTimeUnix: 1,
            totalCallsDispatched: 1,
            totalCallsScheduled: 1,
            lastUpdatedAtUnix: 1,
            status: "pending",
            agentName: "agent_name",
            recipients: [
                {
                    id: "id",
                    phoneNumber: "phone_number",
                    status: "pending",
                    createdAtUnix: 1,
                    updatedAtUnix: 1,
                    conversationId: "conversation_id",
                    conversationInitiationClientData: {
                        conversationConfigOverride: {
                            tts: {
                                voiceId: "cjVigY5qzO86Huf0OWal",
                                stability: 0.5,
                                speed: 1,
                                similarityBoost: 0.8,
                            },
                            conversation: undefined,
                            agent: {
                                firstMessage: "Hello, how can I help you today?",
                                language: "en",
                                prompt: {
                                    prompt: "You are a helpful assistant that can answer questions about the topic of the conversation.",
                                    nativeMcpServerIds: undefined,
                                },
                            },
                        },
                        userId: undefined,
                    },
                },
            ],
        });
    });

    test("cancel", async () => {
        const server = mockServerPool.createServer();
        const client = new ElevenLabsClient({ apiKey: "test", environment: server.baseUrl });

        const rawResponseBody = {
            id: "id",
            phone_number_id: "phone_number_id",
            phone_provider: "twilio",
            name: "name",
            agent_id: "agent_id",
            created_at_unix: 1,
            scheduled_time_unix: 1,
            total_calls_dispatched: 1,
            total_calls_scheduled: 1,
            last_updated_at_unix: 1,
            status: "pending",
            agent_name: "agent_name",
        };
        server
            .mockEndpoint()
            .post("/v1/convai/batch-calling/batch_id/cancel")
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.conversationalAi.batchCalls.cancel("batch_id");
        expect(response).toEqual({
            id: "id",
            phoneNumberId: "phone_number_id",
            phoneProvider: "twilio",
            name: "name",
            agentId: "agent_id",
            createdAtUnix: 1,
            scheduledTimeUnix: 1,
            totalCallsDispatched: 1,
            totalCallsScheduled: 1,
            lastUpdatedAtUnix: 1,
            status: "pending",
            agentName: "agent_name",
        });
    });

    test("retry", async () => {
        const server = mockServerPool.createServer();
        const client = new ElevenLabsClient({ apiKey: "test", environment: server.baseUrl });

        const rawResponseBody = {
            id: "id",
            phone_number_id: "phone_number_id",
            phone_provider: "twilio",
            name: "name",
            agent_id: "agent_id",
            created_at_unix: 1,
            scheduled_time_unix: 1,
            total_calls_dispatched: 1,
            total_calls_scheduled: 1,
            last_updated_at_unix: 1,
            status: "pending",
            agent_name: "agent_name",
        };
        server
            .mockEndpoint()
            .post("/v1/convai/batch-calling/batch_id/retry")
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.conversationalAi.batchCalls.retry("batch_id");
        expect(response).toEqual({
            id: "id",
            phoneNumberId: "phone_number_id",
            phoneProvider: "twilio",
            name: "name",
            agentId: "agent_id",
            createdAtUnix: 1,
            scheduledTimeUnix: 1,
            totalCallsDispatched: 1,
            totalCallsScheduled: 1,
            lastUpdatedAtUnix: 1,
            status: "pending",
            agentName: "agent_name",
        });
    });
});
