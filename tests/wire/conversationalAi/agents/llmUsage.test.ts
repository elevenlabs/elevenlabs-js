/**
 * This file was auto-generated by Fern from our API Definition.
 */

import { mockServerPool } from "../../../mock-server/MockServerPool.js";
import { ElevenLabsClient } from "../../../../src/Client";

describe("LlmUsage", () => {
    test("calculate", async () => {
        const server = mockServerPool.createServer();
        const client = new ElevenLabsClient({
            apiKey: "test",
            environment: { base: server.baseUrl, wss: server.baseUrl },
        });
        const rawRequestBody = {};
        const rawResponseBody = { llm_prices: [{ llm: "gpt-4o-mini", price_per_minute: 1.1 }] };
        server
            .mockEndpoint()
            .post("/v1/convai/agent/agent_id/llm-usage/calculate")
            .jsonBody(rawRequestBody)
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.conversationalAi.agents.llmUsage.calculate("agent_id");
        expect(response).toEqual({
            llmPrices: [
                {
                    llm: "gpt-4o-mini",
                    pricePerMinute: 1.1,
                },
            ],
        });
    });
});
