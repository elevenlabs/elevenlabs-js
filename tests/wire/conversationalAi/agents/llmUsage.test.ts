// This file was auto-generated by Fern from our API Definition.

import { ElevenLabsClient } from "../../../../src/Client";
import { mockServerPool } from "../../../mock-server/MockServerPool";

describe("LlmUsageClient", () => {
    test("calculate", async () => {
        const server = mockServerPool.createServer();
        const client = new ElevenLabsClient({ maxRetries: 0, apiKey: "test", environment: server.baseUrl });
        const rawRequestBody = {};
        const rawResponseBody = { llm_prices: [{ llm: "gpt-4o-mini", price_per_minute: 1.1 }] };
        server
            .mockEndpoint()
            .post("/v1/convai/agent/agent_id/llm-usage/calculate")
            .jsonBody(rawRequestBody)
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.conversationalAi.agents.llmUsage.calculate("agent_id");
        expect(response).toEqual({
            llmPrices: [
                {
                    llm: "gpt-4o-mini",
                    pricePerMinute: 1.1,
                },
            ],
        });
    });
});
