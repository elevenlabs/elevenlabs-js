// This file was auto-generated by Fern from our API Definition.

import { mockServerPool } from "../mock-server/MockServerPool";
import { ElevenLabsClient } from "../../src/Client";

describe("ConversationalAi", () => {
    test("get_document_rag_indexes", async () => {
        const server = mockServerPool.createServer();
        const client = new ElevenLabsClient({ apiKey: "test", environment: server.baseUrl });

        const rawResponseBody = {
            indexes: [
                {
                    id: "id",
                    model: "e5_mistral_7b_instruct",
                    status: "created",
                    progress_percentage: 1.1,
                    document_model_index_usage: { used_bytes: 1 },
                },
            ],
        };
        server
            .mockEndpoint()
            .get("/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/rag-index")
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.conversationalAi.getDocumentRagIndexes("21m00Tcm4TlvDq8ikWAM");
        expect(response).toEqual({
            indexes: [
                {
                    id: "id",
                    model: "e5_mistral_7b_instruct",
                    status: "created",
                    progressPercentage: 1.1,
                    documentModelIndexUsage: {
                        usedBytes: 1,
                    },
                },
            ],
        });
    });

    test("delete_document_rag_index", async () => {
        const server = mockServerPool.createServer();
        const client = new ElevenLabsClient({ apiKey: "test", environment: server.baseUrl });

        const rawResponseBody = {
            id: "id",
            model: "e5_mistral_7b_instruct",
            status: "created",
            progress_percentage: 1.1,
            document_model_index_usage: { used_bytes: 1 },
        };
        server
            .mockEndpoint()
            .delete("/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/rag-index/21m00Tcm4TlvDq8ikWAM")
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.conversationalAi.deleteDocumentRagIndex(
            "21m00Tcm4TlvDq8ikWAM",
            "21m00Tcm4TlvDq8ikWAM",
        );
        expect(response).toEqual({
            id: "id",
            model: "e5_mistral_7b_instruct",
            status: "created",
            progressPercentage: 1.1,
            documentModelIndexUsage: {
                usedBytes: 1,
            },
        });
    });

    test("rag_index_overview", async () => {
        const server = mockServerPool.createServer();
        const client = new ElevenLabsClient({ apiKey: "test", environment: server.baseUrl });

        const rawResponseBody = {
            total_used_bytes: 1,
            total_max_bytes: 1,
            models: [{ model: "e5_mistral_7b_instruct", used_bytes: 1 }],
        };
        server
            .mockEndpoint()
            .get("/v1/convai/knowledge-base/rag-index")
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.conversationalAi.ragIndexOverview();
        expect(response).toEqual({
            totalUsedBytes: 1,
            totalMaxBytes: 1,
            models: [
                {
                    model: "e5_mistral_7b_instruct",
                    usedBytes: 1,
                },
            ],
        });
    });
});
