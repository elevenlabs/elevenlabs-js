// This file was auto-generated by Fern from our API Definition.

import * as serializers from "../index";
import * as ElevenLabs from "../../api/index";
import * as core from "../../core";
import { Llm } from "./Llm";
import { LlmReasoningEffort } from "./LlmReasoningEffort";
import { BuiltInToolsWorkflowOverrideOutput } from "./BuiltInToolsWorkflowOverrideOutput";
import { KnowledgeBaseLocator } from "./KnowledgeBaseLocator";
import { CustomLlm } from "./CustomLlm";
import { RagConfigWorkflowOverride } from "./RagConfigWorkflowOverride";
import { PromptAgentApiModelWorkflowOverrideOutputBackupLlmConfig } from "./PromptAgentApiModelWorkflowOverrideOutputBackupLlmConfig";
import { PromptAgentApiModelWorkflowOverrideOutputToolsItem } from "./PromptAgentApiModelWorkflowOverrideOutputToolsItem";

export const PromptAgentApiModelWorkflowOverrideOutput: core.serialization.ObjectSchema<
    serializers.PromptAgentApiModelWorkflowOverrideOutput.Raw,
    ElevenLabs.PromptAgentApiModelWorkflowOverrideOutput
> = core.serialization.object({
    prompt: core.serialization.string().optional(),
    llm: Llm.optional(),
    reasoningEffort: core.serialization.property("reasoning_effort", LlmReasoningEffort.optional()),
    thinkingBudget: core.serialization.property("thinking_budget", core.serialization.number().optional()),
    temperature: core.serialization.number().optional(),
    maxTokens: core.serialization.property("max_tokens", core.serialization.number().optional()),
    toolIds: core.serialization.property("tool_ids", core.serialization.list(core.serialization.string()).optional()),
    builtInTools: core.serialization.property("built_in_tools", BuiltInToolsWorkflowOverrideOutput.optional()),
    mcpServerIds: core.serialization.property(
        "mcp_server_ids",
        core.serialization.list(core.serialization.string()).optional(),
    ),
    nativeMcpServerIds: core.serialization.property(
        "native_mcp_server_ids",
        core.serialization.list(core.serialization.string()).optional(),
    ),
    knowledgeBase: core.serialization.property(
        "knowledge_base",
        core.serialization.list(KnowledgeBaseLocator).optional(),
    ),
    customLlm: core.serialization.property("custom_llm", CustomLlm.optional()),
    ignoreDefaultPersonality: core.serialization.property(
        "ignore_default_personality",
        core.serialization.boolean().optional(),
    ),
    rag: RagConfigWorkflowOverride.optional(),
    timezone: core.serialization.string().optional(),
    backupLlmConfig: core.serialization.property(
        "backup_llm_config",
        PromptAgentApiModelWorkflowOverrideOutputBackupLlmConfig.optional(),
    ),
    tools: core.serialization.list(PromptAgentApiModelWorkflowOverrideOutputToolsItem).optional(),
});

export declare namespace PromptAgentApiModelWorkflowOverrideOutput {
    export interface Raw {
        prompt?: string | null;
        llm?: Llm.Raw | null;
        reasoning_effort?: LlmReasoningEffort.Raw | null;
        thinking_budget?: number | null;
        temperature?: number | null;
        max_tokens?: number | null;
        tool_ids?: string[] | null;
        built_in_tools?: BuiltInToolsWorkflowOverrideOutput.Raw | null;
        mcp_server_ids?: string[] | null;
        native_mcp_server_ids?: string[] | null;
        knowledge_base?: KnowledgeBaseLocator.Raw[] | null;
        custom_llm?: CustomLlm.Raw | null;
        ignore_default_personality?: boolean | null;
        rag?: RagConfigWorkflowOverride.Raw | null;
        timezone?: string | null;
        backup_llm_config?: PromptAgentApiModelWorkflowOverrideOutputBackupLlmConfig.Raw | null;
        tools?: PromptAgentApiModelWorkflowOverrideOutputToolsItem.Raw[] | null;
    }
}
