/**
 * This file was auto-generated by Fern from our API Definition.
 */

import * as serializers from "../index";
import * as ElevenLabs from "../../api/index";
import * as core from "../../core";
import { ConversationHistoryTranscriptCommonModelOutputRole } from "./ConversationHistoryTranscriptCommonModelOutputRole";
import { ConversationHistoryTranscriptToolCallCommonModel } from "./ConversationHistoryTranscriptToolCallCommonModel";
import { ConversationHistoryTranscriptToolResultCommonModel } from "./ConversationHistoryTranscriptToolResultCommonModel";
import { UserFeedback } from "./UserFeedback";
import { ConversationHistoryTranscriptCommonModelOutputSourceMedium } from "./ConversationHistoryTranscriptCommonModelOutputSourceMedium";
import { ConversationTurnMetrics } from "./ConversationTurnMetrics";
import { RagRetrievalInfo } from "./RagRetrievalInfo";
import { LlmUsageOutput } from "./LlmUsageOutput";

export const ConversationHistoryTranscriptCommonModelOutput: core.serialization.ObjectSchema<
    serializers.ConversationHistoryTranscriptCommonModelOutput.Raw,
    ElevenLabs.ConversationHistoryTranscriptCommonModelOutput
> = core.serialization.object({
    role: ConversationHistoryTranscriptCommonModelOutputRole,
    message: core.serialization.string().optional(),
    toolCalls: core.serialization.property(
        "tool_calls",
        core.serialization.list(ConversationHistoryTranscriptToolCallCommonModel).optional(),
    ),
    toolResults: core.serialization.property(
        "tool_results",
        core.serialization.list(ConversationHistoryTranscriptToolResultCommonModel).optional(),
    ),
    feedback: UserFeedback.optional(),
    llmOverride: core.serialization.property("llm_override", core.serialization.string().optional()),
    sourceMedium: core.serialization.property(
        "source_medium",
        ConversationHistoryTranscriptCommonModelOutputSourceMedium.optional(),
    ),
    timeInCallSecs: core.serialization.property("time_in_call_secs", core.serialization.number()),
    conversationTurnMetrics: core.serialization.property(
        "conversation_turn_metrics",
        ConversationTurnMetrics.optional(),
    ),
    ragRetrievalInfo: core.serialization.property("rag_retrieval_info", RagRetrievalInfo.optional()),
    llmUsage: core.serialization.property("llm_usage", LlmUsageOutput.optional()),
    interrupted: core.serialization.boolean().optional(),
    originalMessage: core.serialization.property("original_message", core.serialization.string().optional()),
});

export declare namespace ConversationHistoryTranscriptCommonModelOutput {
    export interface Raw {
        role: ConversationHistoryTranscriptCommonModelOutputRole.Raw;
        message?: string | null;
        tool_calls?: ConversationHistoryTranscriptToolCallCommonModel.Raw[] | null;
        tool_results?: ConversationHistoryTranscriptToolResultCommonModel.Raw[] | null;
        feedback?: UserFeedback.Raw | null;
        llm_override?: string | null;
        source_medium?: ConversationHistoryTranscriptCommonModelOutputSourceMedium.Raw | null;
        time_in_call_secs: number;
        conversation_turn_metrics?: ConversationTurnMetrics.Raw | null;
        rag_retrieval_info?: RagRetrievalInfo.Raw | null;
        llm_usage?: LlmUsageOutput.Raw | null;
        interrupted?: boolean | null;
        original_message?: string | null;
    }
}
