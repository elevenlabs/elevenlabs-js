// This file was auto-generated by Fern from our API Definition.

import type * as ElevenLabs from "../../api/index";
import * as core from "../../core";
import type * as serializers from "../index";
import { AgentMetadata } from "./AgentMetadata";
import { ConversationHistoryMultivoiceMessageModel } from "./ConversationHistoryMultivoiceMessageModel";
import { ConversationHistoryTranscriptCommonModelOutputRole } from "./ConversationHistoryTranscriptCommonModelOutputRole";
import { ConversationHistoryTranscriptCommonModelOutputSourceMedium } from "./ConversationHistoryTranscriptCommonModelOutputSourceMedium";
import { ConversationHistoryTranscriptCommonModelOutputToolResultsItem } from "./ConversationHistoryTranscriptCommonModelOutputToolResultsItem";
import { ConversationHistoryTranscriptToolCallCommonModelOutput } from "./ConversationHistoryTranscriptToolCallCommonModelOutput";
import { ConversationTurnMetrics } from "./ConversationTurnMetrics";
import { LlmUsageOutput } from "./LlmUsageOutput";
import { RagRetrievalInfo } from "./RagRetrievalInfo";
import { UserFeedback } from "./UserFeedback";

export const ConversationHistoryTranscriptCommonModelOutput: core.serialization.ObjectSchema<
    serializers.ConversationHistoryTranscriptCommonModelOutput.Raw,
    ElevenLabs.ConversationHistoryTranscriptCommonModelOutput
> = core.serialization.object({
    role: ConversationHistoryTranscriptCommonModelOutputRole,
    agentMetadata: core.serialization.property("agent_metadata", AgentMetadata.optional()),
    message: core.serialization.string().optional(),
    multivoiceMessage: core.serialization.property(
        "multivoice_message",
        ConversationHistoryMultivoiceMessageModel.optional(),
    ),
    toolCalls: core.serialization.property(
        "tool_calls",
        core.serialization.list(ConversationHistoryTranscriptToolCallCommonModelOutput).optional(),
    ),
    toolResults: core.serialization.property(
        "tool_results",
        core.serialization.list(ConversationHistoryTranscriptCommonModelOutputToolResultsItem).optional(),
    ),
    feedback: UserFeedback.optional(),
    llmOverride: core.serialization.property("llm_override", core.serialization.string().optional()),
    timeInCallSecs: core.serialization.property("time_in_call_secs", core.serialization.number()),
    conversationTurnMetrics: core.serialization.property(
        "conversation_turn_metrics",
        ConversationTurnMetrics.optional(),
    ),
    ragRetrievalInfo: core.serialization.property("rag_retrieval_info", RagRetrievalInfo.optional()),
    llmUsage: core.serialization.property("llm_usage", LlmUsageOutput.optional()),
    interrupted: core.serialization.boolean().optional(),
    originalMessage: core.serialization.property("original_message", core.serialization.string().optional()),
    sourceMedium: core.serialization.property(
        "source_medium",
        ConversationHistoryTranscriptCommonModelOutputSourceMedium.optional(),
    ),
});

export declare namespace ConversationHistoryTranscriptCommonModelOutput {
    export interface Raw {
        role: ConversationHistoryTranscriptCommonModelOutputRole.Raw;
        agent_metadata?: AgentMetadata.Raw | null;
        message?: string | null;
        multivoice_message?: ConversationHistoryMultivoiceMessageModel.Raw | null;
        tool_calls?: ConversationHistoryTranscriptToolCallCommonModelOutput.Raw[] | null;
        tool_results?: ConversationHistoryTranscriptCommonModelOutputToolResultsItem.Raw[] | null;
        feedback?: UserFeedback.Raw | null;
        llm_override?: string | null;
        time_in_call_secs: number;
        conversation_turn_metrics?: ConversationTurnMetrics.Raw | null;
        rag_retrieval_info?: RagRetrievalInfo.Raw | null;
        llm_usage?: LlmUsageOutput.Raw | null;
        interrupted?: boolean | null;
        original_message?: string | null;
        source_medium?: ConversationHistoryTranscriptCommonModelOutputSourceMedium.Raw | null;
    }
}
