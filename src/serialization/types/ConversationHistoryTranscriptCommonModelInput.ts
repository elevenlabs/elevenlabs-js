/**
 * This file was auto-generated by Fern from our API Definition.
 */

import * as serializers from "../index";
import * as ElevenLabs from "../../api/index";
import * as core from "../../core";
import { ConversationHistoryTranscriptCommonModelInputRole } from "./ConversationHistoryTranscriptCommonModelInputRole";
import { ConversationHistoryTranscriptToolCallCommonModel } from "./ConversationHistoryTranscriptToolCallCommonModel";
import { ConversationHistoryTranscriptCommonModelInputToolResultsItem } from "./ConversationHistoryTranscriptCommonModelInputToolResultsItem";
import { UserFeedback } from "./UserFeedback";
import { ConversationTurnMetrics } from "./ConversationTurnMetrics";
import { RagRetrievalInfo } from "./RagRetrievalInfo";
import { LlmUsageInput } from "./LlmUsageInput";
import { ConversationHistoryTranscriptCommonModelInputSourceMedium } from "./ConversationHistoryTranscriptCommonModelInputSourceMedium";

export const ConversationHistoryTranscriptCommonModelInput: core.serialization.ObjectSchema<
    serializers.ConversationHistoryTranscriptCommonModelInput.Raw,
    ElevenLabs.ConversationHistoryTranscriptCommonModelInput
> = core.serialization.object({
    role: ConversationHistoryTranscriptCommonModelInputRole,
    message: core.serialization.string().optional(),
    toolCalls: core.serialization.property(
        "tool_calls",
        core.serialization.list(ConversationHistoryTranscriptToolCallCommonModel).optional(),
    ),
    toolResults: core.serialization.property(
        "tool_results",
        core.serialization.list(ConversationHistoryTranscriptCommonModelInputToolResultsItem).optional(),
    ),
    feedback: UserFeedback.optional(),
    llmOverride: core.serialization.property("llm_override", core.serialization.string().optional()),
    timeInCallSecs: core.serialization.property("time_in_call_secs", core.serialization.number()),
    conversationTurnMetrics: core.serialization.property(
        "conversation_turn_metrics",
        ConversationTurnMetrics.optional(),
    ),
    ragRetrievalInfo: core.serialization.property("rag_retrieval_info", RagRetrievalInfo.optional()),
    llmUsage: core.serialization.property("llm_usage", LlmUsageInput.optional()),
    interrupted: core.serialization.boolean().optional(),
    originalMessage: core.serialization.property("original_message", core.serialization.string().optional()),
    sourceMedium: core.serialization.property(
        "source_medium",
        ConversationHistoryTranscriptCommonModelInputSourceMedium.optional(),
    ),
});

export declare namespace ConversationHistoryTranscriptCommonModelInput {
    export interface Raw {
        role: ConversationHistoryTranscriptCommonModelInputRole.Raw;
        message?: string | null;
        tool_calls?: ConversationHistoryTranscriptToolCallCommonModel.Raw[] | null;
        tool_results?: ConversationHistoryTranscriptCommonModelInputToolResultsItem.Raw[] | null;
        feedback?: UserFeedback.Raw | null;
        llm_override?: string | null;
        time_in_call_secs: number;
        conversation_turn_metrics?: ConversationTurnMetrics.Raw | null;
        rag_retrieval_info?: RagRetrievalInfo.Raw | null;
        llm_usage?: LlmUsageInput.Raw | null;
        interrupted?: boolean | null;
        original_message?: string | null;
        source_medium?: ConversationHistoryTranscriptCommonModelInputSourceMedium.Raw | null;
    }
}
