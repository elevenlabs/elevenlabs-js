// This file was auto-generated by Fern from our API Definition.

import type * as ElevenLabs from "../../api/index";
import * as core from "../../core";
import type * as serializers from "../index";
import { AgentMetadata } from "./AgentMetadata";
import { ConversationHistoryMultivoiceMessageModel } from "./ConversationHistoryMultivoiceMessageModel";
import { ConversationHistoryTranscriptCommonModelInputRole } from "./ConversationHistoryTranscriptCommonModelInputRole";
import { ConversationHistoryTranscriptCommonModelInputSourceMedium } from "./ConversationHistoryTranscriptCommonModelInputSourceMedium";
import { ConversationHistoryTranscriptCommonModelInputToolResultsItem } from "./ConversationHistoryTranscriptCommonModelInputToolResultsItem";
import { ConversationHistoryTranscriptToolCallCommonModelInput } from "./ConversationHistoryTranscriptToolCallCommonModelInput";
import { ConversationTurnMetrics } from "./ConversationTurnMetrics";
import { LlmUsageInput } from "./LlmUsageInput";
import { RagRetrievalInfo } from "./RagRetrievalInfo";
import { UserFeedback } from "./UserFeedback";

export const ConversationHistoryTranscriptCommonModelInput: core.serialization.ObjectSchema<
    serializers.ConversationHistoryTranscriptCommonModelInput.Raw,
    ElevenLabs.ConversationHistoryTranscriptCommonModelInput
> = core.serialization.object({
    role: ConversationHistoryTranscriptCommonModelInputRole,
    agentMetadata: core.serialization.property("agent_metadata", AgentMetadata.optional()),
    message: core.serialization.string().optional(),
    multivoiceMessage: core.serialization.property(
        "multivoice_message",
        ConversationHistoryMultivoiceMessageModel.optional(),
    ),
    toolCalls: core.serialization.property(
        "tool_calls",
        core.serialization.list(ConversationHistoryTranscriptToolCallCommonModelInput).optional(),
    ),
    toolResults: core.serialization.property(
        "tool_results",
        core.serialization.list(ConversationHistoryTranscriptCommonModelInputToolResultsItem).optional(),
    ),
    feedback: UserFeedback.optional(),
    llmOverride: core.serialization.property("llm_override", core.serialization.string().optional()),
    timeInCallSecs: core.serialization.property("time_in_call_secs", core.serialization.number()),
    conversationTurnMetrics: core.serialization.property(
        "conversation_turn_metrics",
        ConversationTurnMetrics.optional(),
    ),
    ragRetrievalInfo: core.serialization.property("rag_retrieval_info", RagRetrievalInfo.optional()),
    llmUsage: core.serialization.property("llm_usage", LlmUsageInput.optional()),
    interrupted: core.serialization.boolean().optional(),
    originalMessage: core.serialization.property("original_message", core.serialization.string().optional()),
    sourceMedium: core.serialization.property(
        "source_medium",
        ConversationHistoryTranscriptCommonModelInputSourceMedium.optional(),
    ),
});

export declare namespace ConversationHistoryTranscriptCommonModelInput {
    export interface Raw {
        role: ConversationHistoryTranscriptCommonModelInputRole.Raw;
        agent_metadata?: AgentMetadata.Raw | null;
        message?: string | null;
        multivoice_message?: ConversationHistoryMultivoiceMessageModel.Raw | null;
        tool_calls?: ConversationHistoryTranscriptToolCallCommonModelInput.Raw[] | null;
        tool_results?: ConversationHistoryTranscriptCommonModelInputToolResultsItem.Raw[] | null;
        feedback?: UserFeedback.Raw | null;
        llm_override?: string | null;
        time_in_call_secs: number;
        conversation_turn_metrics?: ConversationTurnMetrics.Raw | null;
        rag_retrieval_info?: RagRetrievalInfo.Raw | null;
        llm_usage?: LlmUsageInput.Raw | null;
        interrupted?: boolean | null;
        original_message?: string | null;
        source_medium?: ConversationHistoryTranscriptCommonModelInputSourceMedium.Raw | null;
    }
}
