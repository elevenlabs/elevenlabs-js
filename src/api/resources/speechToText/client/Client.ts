// This file was auto-generated by Fern from our API Definition.

import * as environments from "../../../../environments";
import * as core from "../../../../core";
import * as ElevenLabs from "../../../index";
import * as fs from "fs";
import * as serializers from "../../../../serialization/index";
import { toJson } from "../../../../core/json";
import { mergeHeaders, mergeOnlyDefinedHeaders } from "../../../../core/headers";
import * as errors from "../../../../errors/index";
import { Transcripts } from "../resources/transcripts/client/Client";

export declare namespace SpeechToText {
    export interface Options {
        environment?: core.Supplier<environments.ElevenLabsEnvironment | string>;
        /** Specify a custom URL to connect the client to. */
        baseUrl?: core.Supplier<string>;
        /** Override the xi-api-key header */
        apiKey?: core.Supplier<string | undefined>;
        /** Additional headers to include in requests. */
        headers?: Record<string, string | core.Supplier<string | null | undefined> | null | undefined>;
    }

    export interface RequestOptions {
        /** The maximum time to wait for a response in seconds. */
        timeoutInSeconds?: number;
        /** The number of times to retry the request. Defaults to 2. */
        maxRetries?: number;
        /** A hook to abort the request. */
        abortSignal?: AbortSignal;
        /** Override the xi-api-key header */
        apiKey?: string | undefined;
        /** Additional query string parameters to include in the request. */
        queryParams?: Record<string, unknown>;
        /** Additional headers to include in the request. */
        headers?: Record<string, string | core.Supplier<string | null | undefined> | null | undefined>;
    }
}

export class SpeechToText {
    protected readonly _options: SpeechToText.Options;
    protected _transcripts: Transcripts | undefined;

    constructor(_options: SpeechToText.Options = {}) {
        this._options = _options;
    }

    public get transcripts(): Transcripts {
        return (this._transcripts ??= new Transcripts(this._options));
    }

    /**
     * Transcribe an audio or video file. If webhook is set to true, the request will be processed asynchronously and results sent to configured webhooks. When use_multi_channel is true and the provided audio has multiple channels, a 'transcripts' object with separate transcripts for each channel is returned. Otherwise, returns a single transcript. The optional webhook_metadata parameter allows you to attach custom data that will be included in webhook responses for request correlation and tracking.
     *
     * @param {ElevenLabs.BodySpeechToTextV1SpeechToTextPost} request
     * @param {SpeechToText.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @throws {@link ElevenLabs.UnprocessableEntityError}
     *
     * @example
     *     import { createReadStream } from "fs";
     *     await client.speechToText.convert({
     *         file: fs.createReadStream("/path/to/your/file"),
     *         enableLogging: true,
     *         modelId: "model_id"
     *     })
     */
    public convert(
        request: ElevenLabs.BodySpeechToTextV1SpeechToTextPost,
        requestOptions?: SpeechToText.RequestOptions,
    ): core.HttpResponsePromise<ElevenLabs.SpeechToTextConvertResponse> {
        return core.HttpResponsePromise.fromPromise(this.__convert(request, requestOptions));
    }

    private async __convert(
        request: ElevenLabs.BodySpeechToTextV1SpeechToTextPost,
        requestOptions?: SpeechToText.RequestOptions,
    ): Promise<core.WithRawResponse<ElevenLabs.SpeechToTextConvertResponse>> {
        const _queryParams: Record<string, string | string[] | object | object[] | null> = {};
        if (request.enableLogging != null) {
            _queryParams["enable_logging"] = request.enableLogging.toString();
        }

        const _request = await core.newFormData();
        _request.append("model_id", request.modelId);
        await _request.appendFile("file", request.file);
        if (request.languageCode != null) {
            _request.append("language_code", request.languageCode);
        }

        if (request.tagAudioEvents != null) {
            _request.append("tag_audio_events", request.tagAudioEvents.toString());
        }

        if (request.numSpeakers != null) {
            _request.append("num_speakers", request.numSpeakers.toString());
        }

        if (request.timestampsGranularity != null) {
            _request.append(
                "timestamps_granularity",
                serializers.SpeechToTextConvertRequestTimestampsGranularity.jsonOrThrow(request.timestampsGranularity, {
                    unrecognizedObjectKeys: "strip",
                }),
            );
        }

        if (request.diarize != null) {
            _request.append("diarize", request.diarize.toString());
        }

        if (request.diarizationThreshold != null) {
            _request.append("diarization_threshold", request.diarizationThreshold.toString());
        }

        if (request.additionalFormats != null) {
            _request.append("additional_formats", toJson(request.additionalFormats));
        }

        if (request.fileFormat != null) {
            _request.append(
                "file_format",
                serializers.SpeechToTextConvertRequestFileFormat.jsonOrThrow(request.fileFormat, {
                    unrecognizedObjectKeys: "strip",
                }),
            );
        }

        if (request.cloudStorageUrl != null) {
            _request.append("cloud_storage_url", request.cloudStorageUrl);
        }

        if (request.webhook != null) {
            _request.append("webhook", request.webhook.toString());
        }

        if (request.webhookId != null) {
            _request.append("webhook_id", request.webhookId);
        }

        if (request.temperature != null) {
            _request.append("temperature", request.temperature.toString());
        }

        if (request.seed != null) {
            _request.append("seed", request.seed.toString());
        }

        if (request.useMultiChannel != null) {
            _request.append("use_multi_channel", request.useMultiChannel.toString());
        }

        if (request.webhookMetadata != null) {
            _request.append(
                "webhook_metadata",
                (() => {
                    const mapped = serializers.SpeechToTextConvertRequestWebhookMetadata.jsonOrThrow(
                        request.webhookMetadata,
                        { unrecognizedObjectKeys: "strip" },
                    );
                    return typeof mapped === "string" ? mapped : toJson(mapped);
                })(),
            );
        }

        const _maybeEncodedRequest = await _request.getRequest();
        let _headers: core.Fetcher.Args["headers"] = mergeHeaders(
            this._options?.headers,
            mergeOnlyDefinedHeaders({
                "xi-api-key": requestOptions?.apiKey ?? this._options?.apiKey,
                ..._maybeEncodedRequest.headers,
            }),
            requestOptions?.headers,
        );
        const _response = await core.fetcher({
            url: core.url.join(
                (await core.Supplier.get(this._options.baseUrl)) ??
                    (await core.Supplier.get(this._options.environment)) ??
                    environments.ElevenLabsEnvironment.Production,
                "v1/speech-to-text",
            ),
            method: "POST",
            headers: _headers,
            queryParameters: { ..._queryParams, ...requestOptions?.queryParams },
            requestType: "file",
            duplex: _maybeEncodedRequest.duplex,
            body: _maybeEncodedRequest.body,
            timeoutMs: requestOptions?.timeoutInSeconds != null ? requestOptions.timeoutInSeconds * 1000 : 240000,
            maxRetries: requestOptions?.maxRetries,
            abortSignal: requestOptions?.abortSignal,
        });
        if (_response.ok) {
            return {
                data: serializers.SpeechToTextConvertResponse.parseOrThrow(_response.body, {
                    unrecognizedObjectKeys: "passthrough",
                    allowUnrecognizedUnionMembers: true,
                    allowUnrecognizedEnumValues: true,
                    breadcrumbsPrefix: ["response"],
                }),
                rawResponse: _response.rawResponse,
            };
        }

        if (_response.error.reason === "status-code") {
            switch (_response.error.statusCode) {
                case 422:
                    throw new ElevenLabs.UnprocessableEntityError(
                        serializers.HttpValidationError.parseOrThrow(_response.error.body, {
                            unrecognizedObjectKeys: "passthrough",
                            allowUnrecognizedUnionMembers: true,
                            allowUnrecognizedEnumValues: true,
                            breadcrumbsPrefix: ["response"],
                        }),
                        _response.rawResponse,
                    );
                default:
                    throw new errors.ElevenLabsError({
                        statusCode: _response.error.statusCode,
                        body: _response.error.body,
                        rawResponse: _response.rawResponse,
                    });
            }
        }

        switch (_response.error.reason) {
            case "non-json":
                throw new errors.ElevenLabsError({
                    statusCode: _response.error.statusCode,
                    body: _response.error.rawBody,
                    rawResponse: _response.rawResponse,
                });
            case "timeout":
                throw new errors.ElevenLabsTimeoutError("Timeout exceeded when calling POST /v1/speech-to-text.");
            case "unknown":
                throw new errors.ElevenLabsError({
                    message: _response.error.errorMessage,
                    rawResponse: _response.rawResponse,
                });
        }
    }
}
