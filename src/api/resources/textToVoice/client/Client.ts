// This file was auto-generated by Fern from our API Definition.

import type { BaseClientOptions, BaseRequestOptions } from "../../../../BaseClient";
import { type NormalizedClientOptions, normalizeClientOptions } from "../../../../BaseClient";
import * as core from "../../../../core";
import { mergeHeaders, mergeOnlyDefinedHeaders } from "../../../../core/headers";
import * as environments from "../../../../environments";
import { handleNonStatusCodeError } from "../../../../errors/handleNonStatusCodeError";
import * as errors from "../../../../errors/index";
import * as serializers from "../../../../serialization/index";
import * as ElevenLabs from "../../../index";
import { PreviewClient } from "../resources/preview/client/Client";

export declare namespace TextToVoiceClient {
    export type Options = BaseClientOptions;

    export interface RequestOptions extends BaseRequestOptions {}
}

export class TextToVoiceClient {
    protected readonly _options: NormalizedClientOptions<TextToVoiceClient.Options>;
    protected _preview: PreviewClient | undefined;

    constructor(options: TextToVoiceClient.Options = {}) {
        this._options = normalizeClientOptions(options);
    }

    public get preview(): PreviewClient {
        return (this._preview ??= new PreviewClient(this._options));
    }

    /**
     * Create a voice from a text prompt.
     *
     * @param {ElevenLabs.VoiceDesignRequest} request
     * @param {TextToVoiceClient.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @throws {@link ElevenLabs.UnprocessableEntityError}
     *
     * @example
     *     await client.textToVoice.createPreviews({
     *         outputFormat: "mp3_22050_32",
     *         voiceDescription: "A sassy squeaky mouse"
     *     })
     */
    public createPreviews(
        request: ElevenLabs.VoiceDesignRequest,
        requestOptions?: TextToVoiceClient.RequestOptions,
    ): core.HttpResponsePromise<ElevenLabs.VoiceDesignPreviewResponse> {
        return core.HttpResponsePromise.fromPromise(this.__createPreviews(request, requestOptions));
    }

    private async __createPreviews(
        request: ElevenLabs.VoiceDesignRequest,
        requestOptions?: TextToVoiceClient.RequestOptions,
    ): Promise<core.WithRawResponse<ElevenLabs.VoiceDesignPreviewResponse>> {
        const { outputFormat, ..._body } = request;
        const _queryParams: Record<string, string | string[] | object | object[] | null> = {};
        if (outputFormat != null) {
            _queryParams.output_format = serializers.AllowedOutputFormats.jsonOrThrow(outputFormat, {
                unrecognizedObjectKeys: "strip",
            });
        }

        const _headers: core.Fetcher.Args["headers"] = mergeHeaders(
            this._options?.headers,
            mergeOnlyDefinedHeaders({ "xi-api-key": requestOptions?.apiKey ?? this._options?.apiKey }),
            requestOptions?.headers,
        );
        const _response = await (this._options.fetcher ?? core.fetcher)({
            url: core.url.join(
                (await core.Supplier.get(this._options.baseUrl)) ??
                    (await core.Supplier.get(this._options.environment)) ??
                    environments.ElevenLabsEnvironment.Production,
                "v1/text-to-voice/create-previews",
            ),
            method: "POST",
            headers: _headers,
            contentType: "application/json",
            queryParameters: { ..._queryParams, ...requestOptions?.queryParams },
            requestType: "json",
            body: serializers.VoiceDesignRequest.jsonOrThrow(_body, { unrecognizedObjectKeys: "strip" }),
            timeoutMs: (requestOptions?.timeoutInSeconds ?? this._options?.timeoutInSeconds ?? 240) * 1000,
            maxRetries: requestOptions?.maxRetries ?? this._options?.maxRetries,
            abortSignal: requestOptions?.abortSignal,
            fetchFn: this._options?.fetch,
            logging: this._options.logging,
        });
        if (_response.ok) {
            return {
                data: serializers.VoiceDesignPreviewResponse.parseOrThrow(_response.body, {
                    unrecognizedObjectKeys: "passthrough",
                    allowUnrecognizedUnionMembers: true,
                    allowUnrecognizedEnumValues: true,
                    breadcrumbsPrefix: ["response"],
                }),
                rawResponse: _response.rawResponse,
            };
        }

        if (_response.error.reason === "status-code") {
            switch (_response.error.statusCode) {
                case 422:
                    throw new ElevenLabs.UnprocessableEntityError(
                        serializers.HttpValidationError.parseOrThrow(_response.error.body, {
                            unrecognizedObjectKeys: "passthrough",
                            allowUnrecognizedUnionMembers: true,
                            allowUnrecognizedEnumValues: true,
                            breadcrumbsPrefix: ["response"],
                        }),
                        _response.rawResponse,
                    );
                default:
                    throw new errors.ElevenLabsError({
                        statusCode: _response.error.statusCode,
                        body: _response.error.body,
                        rawResponse: _response.rawResponse,
                    });
            }
        }

        return handleNonStatusCodeError(
            _response.error,
            _response.rawResponse,
            "POST",
            "/v1/text-to-voice/create-previews",
        );
    }

    /**
     * Create a voice from previously generated voice preview. This endpoint should be called after you fetched a generated_voice_id using POST /v1/text-to-voice/design or POST /v1/text-to-voice/:voice_id/remix.
     *
     * @param {ElevenLabs.BodyCreateANewVoiceFromVoicePreviewV1TextToVoicePost} request
     * @param {TextToVoiceClient.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @throws {@link ElevenLabs.UnprocessableEntityError}
     *
     * @example
     *     await client.textToVoice.create({
     *         voiceName: "Sassy squeaky mouse",
     *         voiceDescription: "A sassy squeaky mouse",
     *         generatedVoiceId: "37HceQefKmEi3bGovXjL"
     *     })
     */
    public create(
        request: ElevenLabs.BodyCreateANewVoiceFromVoicePreviewV1TextToVoicePost,
        requestOptions?: TextToVoiceClient.RequestOptions,
    ): core.HttpResponsePromise<ElevenLabs.Voice> {
        return core.HttpResponsePromise.fromPromise(this.__create(request, requestOptions));
    }

    private async __create(
        request: ElevenLabs.BodyCreateANewVoiceFromVoicePreviewV1TextToVoicePost,
        requestOptions?: TextToVoiceClient.RequestOptions,
    ): Promise<core.WithRawResponse<ElevenLabs.Voice>> {
        const _headers: core.Fetcher.Args["headers"] = mergeHeaders(
            this._options?.headers,
            mergeOnlyDefinedHeaders({ "xi-api-key": requestOptions?.apiKey ?? this._options?.apiKey }),
            requestOptions?.headers,
        );
        const _response = await (this._options.fetcher ?? core.fetcher)({
            url: core.url.join(
                (await core.Supplier.get(this._options.baseUrl)) ??
                    (await core.Supplier.get(this._options.environment)) ??
                    environments.ElevenLabsEnvironment.Production,
                "v1/text-to-voice",
            ),
            method: "POST",
            headers: _headers,
            contentType: "application/json",
            queryParameters: requestOptions?.queryParams,
            requestType: "json",
            body: serializers.BodyCreateANewVoiceFromVoicePreviewV1TextToVoicePost.jsonOrThrow(request, {
                unrecognizedObjectKeys: "strip",
            }),
            timeoutMs: (requestOptions?.timeoutInSeconds ?? this._options?.timeoutInSeconds ?? 240) * 1000,
            maxRetries: requestOptions?.maxRetries ?? this._options?.maxRetries,
            abortSignal: requestOptions?.abortSignal,
            fetchFn: this._options?.fetch,
            logging: this._options.logging,
        });
        if (_response.ok) {
            return {
                data: serializers.Voice.parseOrThrow(_response.body, {
                    unrecognizedObjectKeys: "passthrough",
                    allowUnrecognizedUnionMembers: true,
                    allowUnrecognizedEnumValues: true,
                    breadcrumbsPrefix: ["response"],
                }),
                rawResponse: _response.rawResponse,
            };
        }

        if (_response.error.reason === "status-code") {
            switch (_response.error.statusCode) {
                case 422:
                    throw new ElevenLabs.UnprocessableEntityError(
                        serializers.HttpValidationError.parseOrThrow(_response.error.body, {
                            unrecognizedObjectKeys: "passthrough",
                            allowUnrecognizedUnionMembers: true,
                            allowUnrecognizedEnumValues: true,
                            breadcrumbsPrefix: ["response"],
                        }),
                        _response.rawResponse,
                    );
                default:
                    throw new errors.ElevenLabsError({
                        statusCode: _response.error.statusCode,
                        body: _response.error.body,
                        rawResponse: _response.rawResponse,
                    });
            }
        }

        return handleNonStatusCodeError(_response.error, _response.rawResponse, "POST", "/v1/text-to-voice");
    }

    /**
     * Design a voice via a prompt. This method returns a list of voice previews. Each preview has a generated_voice_id and a sample of the voice as base64 encoded mp3 audio. To create a voice use the generated_voice_id of the preferred preview with the /v1/text-to-voice endpoint.
     *
     * @param {ElevenLabs.VoiceDesignRequestModel} request
     * @param {TextToVoiceClient.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @throws {@link ElevenLabs.UnprocessableEntityError}
     *
     * @example
     *     await client.textToVoice.design({
     *         outputFormat: "mp3_22050_32",
     *         voiceDescription: "A sassy squeaky mouse"
     *     })
     */
    public design(
        request: ElevenLabs.VoiceDesignRequestModel,
        requestOptions?: TextToVoiceClient.RequestOptions,
    ): core.HttpResponsePromise<ElevenLabs.VoiceDesignPreviewResponse> {
        return core.HttpResponsePromise.fromPromise(this.__design(request, requestOptions));
    }

    private async __design(
        request: ElevenLabs.VoiceDesignRequestModel,
        requestOptions?: TextToVoiceClient.RequestOptions,
    ): Promise<core.WithRawResponse<ElevenLabs.VoiceDesignPreviewResponse>> {
        const { outputFormat, ..._body } = request;
        const _queryParams: Record<string, string | string[] | object | object[] | null> = {};
        if (outputFormat != null) {
            _queryParams.output_format = serializers.AllowedOutputFormats.jsonOrThrow(outputFormat, {
                unrecognizedObjectKeys: "strip",
            });
        }

        const _headers: core.Fetcher.Args["headers"] = mergeHeaders(
            this._options?.headers,
            mergeOnlyDefinedHeaders({ "xi-api-key": requestOptions?.apiKey ?? this._options?.apiKey }),
            requestOptions?.headers,
        );
        const _response = await (this._options.fetcher ?? core.fetcher)({
            url: core.url.join(
                (await core.Supplier.get(this._options.baseUrl)) ??
                    (await core.Supplier.get(this._options.environment)) ??
                    environments.ElevenLabsEnvironment.Production,
                "v1/text-to-voice/design",
            ),
            method: "POST",
            headers: _headers,
            contentType: "application/json",
            queryParameters: { ..._queryParams, ...requestOptions?.queryParams },
            requestType: "json",
            body: serializers.VoiceDesignRequestModel.jsonOrThrow(_body, { unrecognizedObjectKeys: "strip" }),
            timeoutMs: (requestOptions?.timeoutInSeconds ?? this._options?.timeoutInSeconds ?? 240) * 1000,
            maxRetries: requestOptions?.maxRetries ?? this._options?.maxRetries,
            abortSignal: requestOptions?.abortSignal,
            fetchFn: this._options?.fetch,
            logging: this._options.logging,
        });
        if (_response.ok) {
            return {
                data: serializers.VoiceDesignPreviewResponse.parseOrThrow(_response.body, {
                    unrecognizedObjectKeys: "passthrough",
                    allowUnrecognizedUnionMembers: true,
                    allowUnrecognizedEnumValues: true,
                    breadcrumbsPrefix: ["response"],
                }),
                rawResponse: _response.rawResponse,
            };
        }

        if (_response.error.reason === "status-code") {
            switch (_response.error.statusCode) {
                case 422:
                    throw new ElevenLabs.UnprocessableEntityError(
                        serializers.HttpValidationError.parseOrThrow(_response.error.body, {
                            unrecognizedObjectKeys: "passthrough",
                            allowUnrecognizedUnionMembers: true,
                            allowUnrecognizedEnumValues: true,
                            breadcrumbsPrefix: ["response"],
                        }),
                        _response.rawResponse,
                    );
                default:
                    throw new errors.ElevenLabsError({
                        statusCode: _response.error.statusCode,
                        body: _response.error.body,
                        rawResponse: _response.rawResponse,
                    });
            }
        }

        return handleNonStatusCodeError(_response.error, _response.rawResponse, "POST", "/v1/text-to-voice/design");
    }

    /**
     * Remix an existing voice via a prompt. This method returns a list of voice previews. Each preview has a generated_voice_id and a sample of the voice as base64 encoded mp3 audio. To create a voice use the generated_voice_id of the preferred preview with the /v1/text-to-voice endpoint.
     *
     * @param {string} voice_id - Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.
     * @param {ElevenLabs.VoiceRemixRequestModel} request
     * @param {TextToVoiceClient.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @throws {@link ElevenLabs.UnprocessableEntityError}
     *
     * @example
     *     await client.textToVoice.remix("21m00Tcm4TlvDq8ikWAM", {
     *         outputFormat: "mp3_22050_32",
     *         voiceDescription: "Make the voice have a higher pitch."
     *     })
     */
    public remix(
        voice_id: string,
        request: ElevenLabs.VoiceRemixRequestModel,
        requestOptions?: TextToVoiceClient.RequestOptions,
    ): core.HttpResponsePromise<ElevenLabs.VoiceDesignPreviewResponse> {
        return core.HttpResponsePromise.fromPromise(this.__remix(voice_id, request, requestOptions));
    }

    private async __remix(
        voice_id: string,
        request: ElevenLabs.VoiceRemixRequestModel,
        requestOptions?: TextToVoiceClient.RequestOptions,
    ): Promise<core.WithRawResponse<ElevenLabs.VoiceDesignPreviewResponse>> {
        const { outputFormat, ..._body } = request;
        const _queryParams: Record<string, string | string[] | object | object[] | null> = {};
        if (outputFormat != null) {
            _queryParams.output_format = serializers.AllowedOutputFormats.jsonOrThrow(outputFormat, {
                unrecognizedObjectKeys: "strip",
            });
        }

        const _headers: core.Fetcher.Args["headers"] = mergeHeaders(
            this._options?.headers,
            mergeOnlyDefinedHeaders({ "xi-api-key": requestOptions?.apiKey ?? this._options?.apiKey }),
            requestOptions?.headers,
        );
        const _response = await (this._options.fetcher ?? core.fetcher)({
            url: core.url.join(
                (await core.Supplier.get(this._options.baseUrl)) ??
                    (await core.Supplier.get(this._options.environment)) ??
                    environments.ElevenLabsEnvironment.Production,
                `v1/text-to-voice/${core.url.encodePathParam(voice_id)}/remix`,
            ),
            method: "POST",
            headers: _headers,
            contentType: "application/json",
            queryParameters: { ..._queryParams, ...requestOptions?.queryParams },
            requestType: "json",
            body: serializers.VoiceRemixRequestModel.jsonOrThrow(_body, { unrecognizedObjectKeys: "strip" }),
            timeoutMs: (requestOptions?.timeoutInSeconds ?? this._options?.timeoutInSeconds ?? 240) * 1000,
            maxRetries: requestOptions?.maxRetries ?? this._options?.maxRetries,
            abortSignal: requestOptions?.abortSignal,
            fetchFn: this._options?.fetch,
            logging: this._options.logging,
        });
        if (_response.ok) {
            return {
                data: serializers.VoiceDesignPreviewResponse.parseOrThrow(_response.body, {
                    unrecognizedObjectKeys: "passthrough",
                    allowUnrecognizedUnionMembers: true,
                    allowUnrecognizedEnumValues: true,
                    breadcrumbsPrefix: ["response"],
                }),
                rawResponse: _response.rawResponse,
            };
        }

        if (_response.error.reason === "status-code") {
            switch (_response.error.statusCode) {
                case 422:
                    throw new ElevenLabs.UnprocessableEntityError(
                        serializers.HttpValidationError.parseOrThrow(_response.error.body, {
                            unrecognizedObjectKeys: "passthrough",
                            allowUnrecognizedUnionMembers: true,
                            allowUnrecognizedEnumValues: true,
                            breadcrumbsPrefix: ["response"],
                        }),
                        _response.rawResponse,
                    );
                default:
                    throw new errors.ElevenLabsError({
                        statusCode: _response.error.statusCode,
                        body: _response.error.body,
                        rawResponse: _response.rawResponse,
                    });
            }
        }

        return handleNonStatusCodeError(
            _response.error,
            _response.rawResponse,
            "POST",
            "/v1/text-to-voice/{voice_id}/remix",
        );
    }
}
