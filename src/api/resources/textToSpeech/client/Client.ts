// This file was auto-generated by Fern from our API Definition.

import * as environments from "../../../../environments";
import * as core from "../../../../core";
import * as ElevenLabs from "../../../index";
import * as serializers from "../../../../serialization/index";
import { mergeHeaders, mergeOnlyDefinedHeaders } from "../../../../core/headers";
import * as errors from "../../../../errors/index";

export declare namespace TextToSpeech {
    export interface Options {
        environment?: core.Supplier<environments.ElevenLabsEnvironment | string>;
        /** Specify a custom URL to connect the client to. */
        baseUrl?: core.Supplier<string>;
        /** Override the xi-api-key header */
        apiKey?: core.Supplier<string | undefined>;
        /** Additional headers to include in requests. */
        headers?: Record<string, string | core.Supplier<string | null | undefined> | null | undefined>;
    }

    export interface RequestOptions {
        /** The maximum time to wait for a response in seconds. */
        timeoutInSeconds?: number;
        /** The number of times to retry the request. Defaults to 2. */
        maxRetries?: number;
        /** A hook to abort the request. */
        abortSignal?: AbortSignal;
        /** Override the xi-api-key header */
        apiKey?: string | undefined;
        /** Additional query string parameters to include in the request. */
        queryParams?: Record<string, unknown>;
        /** Additional headers to include in the request. */
        headers?: Record<string, string | core.Supplier<string | null | undefined> | null | undefined>;
    }
}

export class TextToSpeech {
    protected readonly _options: TextToSpeech.Options;

    constructor(_options: TextToSpeech.Options = {}) {
        this._options = _options;
    }

    /**
     * Converts text into speech using a voice of your choice and returns audio.
     * @throws {@link ElevenLabs.UnprocessableEntityError}
     */
    public convert(
        voiceId: string,
        request: ElevenLabs.BodyTextToSpeechFull,
        requestOptions?: TextToSpeech.RequestOptions,
    ): core.HttpResponsePromise<ReadableStream<Uint8Array>> {
        return core.HttpResponsePromise.fromPromise(this.__convert(voiceId, request, requestOptions));
    }

    private async __convert(
        voiceId: string,
        request: ElevenLabs.BodyTextToSpeechFull,
        requestOptions?: TextToSpeech.RequestOptions,
    ): Promise<core.WithRawResponse<ReadableStream<Uint8Array>>> {
        const { enableLogging, optimizeStreamingLatency, outputFormat, ..._body } = request;
        const _queryParams: Record<string, string | string[] | object | object[] | null> = {};
        if (enableLogging != null) {
            _queryParams["enable_logging"] = enableLogging.toString();
        }

        if (optimizeStreamingLatency != null) {
            _queryParams["optimize_streaming_latency"] = optimizeStreamingLatency.toString();
        }

        if (outputFormat != null) {
            _queryParams["output_format"] = serializers.TextToSpeechConvertRequestOutputFormat.jsonOrThrow(
                outputFormat,
                { unrecognizedObjectKeys: "strip" },
            );
        }

        let _headers: core.Fetcher.Args["headers"] = mergeHeaders(
            this._options?.headers,
            mergeOnlyDefinedHeaders({ "xi-api-key": requestOptions?.apiKey ?? this._options?.apiKey }),
            requestOptions?.headers,
        );
        const _response = await core.fetcher<ReadableStream<Uint8Array>>({
            url: core.url.join(
                (await core.Supplier.get(this._options.baseUrl)) ??
                    (await core.Supplier.get(this._options.environment)) ??
                    environments.ElevenLabsEnvironment.Production,
                `v1/text-to-speech/${encodeURIComponent(voiceId)}`,
            ),
            method: "POST",
            headers: _headers,
            contentType: "application/json",
            queryParameters: { ..._queryParams, ...requestOptions?.queryParams },
            requestType: "json",
            body: serializers.BodyTextToSpeechFull.jsonOrThrow(_body, { unrecognizedObjectKeys: "strip" }),
            responseType: "streaming",
            timeoutMs: requestOptions?.timeoutInSeconds != null ? requestOptions.timeoutInSeconds * 1000 : 240000,
            maxRetries: requestOptions?.maxRetries,
            abortSignal: requestOptions?.abortSignal,
        });
        if (_response.ok) {
            return { data: _response.body, rawResponse: _response.rawResponse };
        }

        if (_response.error.reason === "status-code") {
            switch (_response.error.statusCode) {
                case 422:
                    throw new ElevenLabs.UnprocessableEntityError(
                        serializers.HttpValidationError.parseOrThrow(_response.error.body, {
                            unrecognizedObjectKeys: "passthrough",
                            allowUnrecognizedUnionMembers: true,
                            allowUnrecognizedEnumValues: true,
                            breadcrumbsPrefix: ["response"],
                        }),
                        _response.rawResponse,
                    );
                default:
                    throw new errors.ElevenLabsError({
                        statusCode: _response.error.statusCode,
                        body: _response.error.body,
                        rawResponse: _response.rawResponse,
                    });
            }
        }

        switch (_response.error.reason) {
            case "non-json":
                throw new errors.ElevenLabsError({
                    statusCode: _response.error.statusCode,
                    body: _response.error.rawBody,
                    rawResponse: _response.rawResponse,
                });
            case "timeout":
                throw new errors.ElevenLabsTimeoutError(
                    "Timeout exceeded when calling POST /v1/text-to-speech/{voice_id}.",
                );
            case "unknown":
                throw new errors.ElevenLabsError({
                    message: _response.error.errorMessage,
                    rawResponse: _response.rawResponse,
                });
        }
    }

    /**
     * Generate speech from text with precise character-level timing information for audio-text synchronization.
     *
     * @param {string} voiceId - Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.
     * @param {ElevenLabs.BodyTextToSpeechFullWithTimestamps} request
     * @param {TextToSpeech.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @throws {@link ElevenLabs.UnprocessableEntityError}
     *
     * @example
     *     await client.textToSpeech.convertWithTimestamps("21m00Tcm4TlvDq8ikWAM", {
     *         enableLogging: true,
     *         optimizeStreamingLatency: 1,
     *         outputFormat: "mp3_22050_32",
     *         text: "This is a test for the API of ElevenLabs."
     *     })
     */
    public convertWithTimestamps(
        voiceId: string,
        request: ElevenLabs.BodyTextToSpeechFullWithTimestamps,
        requestOptions?: TextToSpeech.RequestOptions,
    ): core.HttpResponsePromise<ElevenLabs.AudioWithTimestampsResponse> {
        return core.HttpResponsePromise.fromPromise(this.__convertWithTimestamps(voiceId, request, requestOptions));
    }

    private async __convertWithTimestamps(
        voiceId: string,
        request: ElevenLabs.BodyTextToSpeechFullWithTimestamps,
        requestOptions?: TextToSpeech.RequestOptions,
    ): Promise<core.WithRawResponse<ElevenLabs.AudioWithTimestampsResponse>> {
        const { enableLogging, optimizeStreamingLatency, outputFormat, ..._body } = request;
        const _queryParams: Record<string, string | string[] | object | object[] | null> = {};
        if (enableLogging != null) {
            _queryParams["enable_logging"] = enableLogging.toString();
        }

        if (optimizeStreamingLatency != null) {
            _queryParams["optimize_streaming_latency"] = optimizeStreamingLatency.toString();
        }

        if (outputFormat != null) {
            _queryParams["output_format"] =
                serializers.TextToSpeechConvertWithTimestampsRequestOutputFormat.jsonOrThrow(outputFormat, {
                    unrecognizedObjectKeys: "strip",
                });
        }

        let _headers: core.Fetcher.Args["headers"] = mergeHeaders(
            this._options?.headers,
            mergeOnlyDefinedHeaders({ "xi-api-key": requestOptions?.apiKey ?? this._options?.apiKey }),
            requestOptions?.headers,
        );
        const _response = await core.fetcher({
            url: core.url.join(
                (await core.Supplier.get(this._options.baseUrl)) ??
                    (await core.Supplier.get(this._options.environment)) ??
                    environments.ElevenLabsEnvironment.Production,
                `v1/text-to-speech/${encodeURIComponent(voiceId)}/with-timestamps`,
            ),
            method: "POST",
            headers: _headers,
            contentType: "application/json",
            queryParameters: { ..._queryParams, ...requestOptions?.queryParams },
            requestType: "json",
            body: serializers.BodyTextToSpeechFullWithTimestamps.jsonOrThrow(_body, {
                unrecognizedObjectKeys: "strip",
            }),
            timeoutMs: requestOptions?.timeoutInSeconds != null ? requestOptions.timeoutInSeconds * 1000 : 240000,
            maxRetries: requestOptions?.maxRetries,
            abortSignal: requestOptions?.abortSignal,
        });
        if (_response.ok) {
            return {
                data: serializers.AudioWithTimestampsResponse.parseOrThrow(_response.body, {
                    unrecognizedObjectKeys: "passthrough",
                    allowUnrecognizedUnionMembers: true,
                    allowUnrecognizedEnumValues: true,
                    breadcrumbsPrefix: ["response"],
                }),
                rawResponse: _response.rawResponse,
            };
        }

        if (_response.error.reason === "status-code") {
            switch (_response.error.statusCode) {
                case 422:
                    throw new ElevenLabs.UnprocessableEntityError(
                        serializers.HttpValidationError.parseOrThrow(_response.error.body, {
                            unrecognizedObjectKeys: "passthrough",
                            allowUnrecognizedUnionMembers: true,
                            allowUnrecognizedEnumValues: true,
                            breadcrumbsPrefix: ["response"],
                        }),
                        _response.rawResponse,
                    );
                default:
                    throw new errors.ElevenLabsError({
                        statusCode: _response.error.statusCode,
                        body: _response.error.body,
                        rawResponse: _response.rawResponse,
                    });
            }
        }

        switch (_response.error.reason) {
            case "non-json":
                throw new errors.ElevenLabsError({
                    statusCode: _response.error.statusCode,
                    body: _response.error.rawBody,
                    rawResponse: _response.rawResponse,
                });
            case "timeout":
                throw new errors.ElevenLabsTimeoutError(
                    "Timeout exceeded when calling POST /v1/text-to-speech/{voice_id}/with-timestamps.",
                );
            case "unknown":
                throw new errors.ElevenLabsError({
                    message: _response.error.errorMessage,
                    rawResponse: _response.rawResponse,
                });
        }
    }

    /**
     * Converts text into speech using a voice of your choice and returns audio as an audio stream.
     * @throws {@link ElevenLabs.UnprocessableEntityError}
     */
    public stream(
        voiceId: string,
        request: ElevenLabs.StreamTextToSpeechRequest,
        requestOptions?: TextToSpeech.RequestOptions,
    ): core.HttpResponsePromise<ReadableStream<Uint8Array>> {
        return core.HttpResponsePromise.fromPromise(this.__stream(voiceId, request, requestOptions));
    }

    private async __stream(
        voiceId: string,
        request: ElevenLabs.StreamTextToSpeechRequest,
        requestOptions?: TextToSpeech.RequestOptions,
    ): Promise<core.WithRawResponse<ReadableStream<Uint8Array>>> {
        const { enableLogging, optimizeStreamingLatency, outputFormat, ..._body } = request;
        const _queryParams: Record<string, string | string[] | object | object[] | null> = {};
        if (enableLogging != null) {
            _queryParams["enable_logging"] = enableLogging.toString();
        }

        if (optimizeStreamingLatency != null) {
            _queryParams["optimize_streaming_latency"] = optimizeStreamingLatency.toString();
        }

        if (outputFormat != null) {
            _queryParams["output_format"] = serializers.TextToSpeechStreamRequestOutputFormat.jsonOrThrow(
                outputFormat,
                { unrecognizedObjectKeys: "strip" },
            );
        }

        let _headers: core.Fetcher.Args["headers"] = mergeHeaders(
            this._options?.headers,
            mergeOnlyDefinedHeaders({ "xi-api-key": requestOptions?.apiKey ?? this._options?.apiKey }),
            requestOptions?.headers,
        );
        const _response = await core.fetcher<ReadableStream<Uint8Array>>({
            url: core.url.join(
                (await core.Supplier.get(this._options.baseUrl)) ??
                    (await core.Supplier.get(this._options.environment)) ??
                    environments.ElevenLabsEnvironment.Production,
                `v1/text-to-speech/${encodeURIComponent(voiceId)}/stream`,
            ),
            method: "POST",
            headers: _headers,
            contentType: "application/json",
            queryParameters: { ..._queryParams, ...requestOptions?.queryParams },
            requestType: "json",
            body: serializers.StreamTextToSpeechRequest.jsonOrThrow(_body, { unrecognizedObjectKeys: "strip" }),
            responseType: "streaming",
            timeoutMs: requestOptions?.timeoutInSeconds != null ? requestOptions.timeoutInSeconds * 1000 : 240000,
            maxRetries: requestOptions?.maxRetries,
            abortSignal: requestOptions?.abortSignal,
        });
        if (_response.ok) {
            return { data: _response.body, rawResponse: _response.rawResponse };
        }

        if (_response.error.reason === "status-code") {
            switch (_response.error.statusCode) {
                case 422:
                    throw new ElevenLabs.UnprocessableEntityError(
                        serializers.HttpValidationError.parseOrThrow(_response.error.body, {
                            unrecognizedObjectKeys: "passthrough",
                            allowUnrecognizedUnionMembers: true,
                            allowUnrecognizedEnumValues: true,
                            breadcrumbsPrefix: ["response"],
                        }),
                        _response.rawResponse,
                    );
                default:
                    throw new errors.ElevenLabsError({
                        statusCode: _response.error.statusCode,
                        body: _response.error.body,
                        rawResponse: _response.rawResponse,
                    });
            }
        }

        switch (_response.error.reason) {
            case "non-json":
                throw new errors.ElevenLabsError({
                    statusCode: _response.error.statusCode,
                    body: _response.error.rawBody,
                    rawResponse: _response.rawResponse,
                });
            case "timeout":
                throw new errors.ElevenLabsTimeoutError(
                    "Timeout exceeded when calling POST /v1/text-to-speech/{voice_id}/stream.",
                );
            case "unknown":
                throw new errors.ElevenLabsError({
                    message: _response.error.errorMessage,
                    rawResponse: _response.rawResponse,
                });
        }
    }

    /**
     * Converts text into speech using a voice of your choice and returns a stream of JSONs containing audio as a base64 encoded string together with information on when which character was spoken.
     */
    public streamWithTimestamps(
        voiceId: string,
        request: ElevenLabs.StreamTextToSpeechWithTimestampsRequest,
        requestOptions?: TextToSpeech.RequestOptions,
    ): core.HttpResponsePromise<core.Stream<ElevenLabs.StreamingAudioChunkWithTimestampsResponse>> {
        return core.HttpResponsePromise.fromPromise(this.__streamWithTimestamps(voiceId, request, requestOptions));
    }

    private async __streamWithTimestamps(
        voiceId: string,
        request: ElevenLabs.StreamTextToSpeechWithTimestampsRequest,
        requestOptions?: TextToSpeech.RequestOptions,
    ): Promise<core.WithRawResponse<core.Stream<ElevenLabs.StreamingAudioChunkWithTimestampsResponse>>> {
        const { enableLogging, optimizeStreamingLatency, outputFormat, ..._body } = request;
        const _queryParams: Record<string, string | string[] | object | object[] | null> = {};
        if (enableLogging != null) {
            _queryParams["enable_logging"] = enableLogging.toString();
        }

        if (optimizeStreamingLatency != null) {
            _queryParams["optimize_streaming_latency"] = optimizeStreamingLatency.toString();
        }

        if (outputFormat != null) {
            _queryParams["output_format"] = serializers.TextToSpeechStreamWithTimestampsRequestOutputFormat.jsonOrThrow(
                outputFormat,
                { unrecognizedObjectKeys: "strip" },
            );
        }

        let _headers: core.Fetcher.Args["headers"] = mergeHeaders(
            this._options?.headers,
            mergeOnlyDefinedHeaders({ "xi-api-key": requestOptions?.apiKey ?? this._options?.apiKey }),
            requestOptions?.headers,
        );
        const _response = await core.fetcher<ReadableStream>({
            url: core.url.join(
                (await core.Supplier.get(this._options.baseUrl)) ??
                    (await core.Supplier.get(this._options.environment)) ??
                    environments.ElevenLabsEnvironment.Production,
                `v1/text-to-speech/${encodeURIComponent(voiceId)}/stream/with-timestamps`,
            ),
            method: "POST",
            headers: _headers,
            contentType: "application/json",
            queryParameters: { ..._queryParams, ...requestOptions?.queryParams },
            requestType: "json",
            body: serializers.StreamTextToSpeechWithTimestampsRequest.jsonOrThrow(_body, {
                unrecognizedObjectKeys: "strip",
            }),
            responseType: "sse",
            timeoutMs: requestOptions?.timeoutInSeconds != null ? requestOptions.timeoutInSeconds * 1000 : 240000,
            maxRetries: requestOptions?.maxRetries,
            abortSignal: requestOptions?.abortSignal,
        });
        if (_response.ok) {
            return {
                data: new core.Stream({
                    stream: _response.body,
                    parse: async (data) => {
                        return serializers.StreamingAudioChunkWithTimestampsResponse.parseOrThrow(data, {
                            unrecognizedObjectKeys: "passthrough",
                            allowUnrecognizedUnionMembers: true,
                            allowUnrecognizedEnumValues: true,
                            breadcrumbsPrefix: ["response"],
                        });
                    },
                    signal: requestOptions?.abortSignal,
                    eventShape: {
                        type: "json",
                        messageTerminator: "\n",
                    },
                }),
                rawResponse: _response.rawResponse,
            };
        }

        if (_response.error.reason === "status-code") {
            switch (_response.error.statusCode) {
                case 422:
                    throw new ElevenLabs.UnprocessableEntityError(
                        serializers.HttpValidationError.parseOrThrow(_response.error.body, {
                            unrecognizedObjectKeys: "passthrough",
                            allowUnrecognizedUnionMembers: true,
                            allowUnrecognizedEnumValues: true,
                            breadcrumbsPrefix: ["response"],
                        }),
                        _response.rawResponse,
                    );
                default:
                    throw new errors.ElevenLabsError({
                        statusCode: _response.error.statusCode,
                        body: _response.error.body,
                        rawResponse: _response.rawResponse,
                    });
            }
        }

        switch (_response.error.reason) {
            case "non-json":
                throw new errors.ElevenLabsError({
                    statusCode: _response.error.statusCode,
                    body: _response.error.rawBody,
                    rawResponse: _response.rawResponse,
                });
            case "timeout":
                throw new errors.ElevenLabsTimeoutError(
                    "Timeout exceeded when calling POST /v1/text-to-speech/{voice_id}/stream/with-timestamps.",
                );
            case "unknown":
                throw new errors.ElevenLabsError({
                    message: _response.error.errorMessage,
                    rawResponse: _response.rawResponse,
                });
        }
    }
}
