/**
 * This file was auto-generated by Fern from our API Definition.
 */

import * as ElevenLabs from "../../../../../../index";

/**
 * @example
 *     {
 *         chatHistory: [{
 *                 role: "user",
 *                 timeInCallSecs: 1
 *             }],
 *         successCondition: "success_condition",
 *         successExamples: [{
 *                 response: "response",
 *                 type: "success"
 *             }],
 *         failureExamples: [{
 *                 response: "response",
 *                 type: "failure"
 *             }],
 *         name: "name"
 *     }
 */
export interface UpdateUnitTestRequest {
    chatHistory: ElevenLabs.ConversationHistoryTranscriptCommonModelInput[];
    /** A prompt that evaluates whether the agent's response is successful. Should return True or False. */
    successCondition: string;
    /** Non-empty list of example responses that should be considered successful */
    successExamples: ElevenLabs.AgentSuccessfulResponseExample[];
    /** Non-empty list of example responses that should be considered failures */
    failureExamples: ElevenLabs.AgentFailureResponseExample[];
    /** How to evaluate the agent's tool call (if any). If empty, the tool call is not evaluated. */
    toolCallParameters?: ElevenLabs.UnitTestToolCallEvaluationModelInput;
    /** Dynamic variables to replace in the agent config during testing */
    dynamicVariables?: Record<
        string,
        ElevenLabs.conversationalAi.UpdateUnitTestRequestDynamicVariablesValue | undefined
    >;
    type?: ElevenLabs.UnitTestCommonModelType;
    /** Metadata of a conversation this test was created from (if applicable). */
    fromConversationMetadata?: ElevenLabs.TestFromConversationMetadataInput;
    name: string;
}
