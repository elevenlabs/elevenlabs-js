imports:
  root: __package__.yml
types:
  SpeechToSpeechConvertRequestFileFormat:
    enum:
      - pcm_s16le_16
      - other
    inline: true
    source:
      openapi: ../openapi.json
  SpeechToSpeechConvertAsStreamRequestFileFormat:
    enum:
      - pcm_s16le_16
      - other
    inline: true
    source:
      openapi: ../openapi.json
service:
  auth: false
  base-path: ''
  endpoints:
    convert:
      path: /v1/speech-to-speech/{voice_id}
      method: POST
      auth: false
      docs: >-
        Transform audio from one voice to another. Maintain full control over
        emotion, timing and delivery.
      source:
        openapi: ../openapi.json
      path-parameters:
        voice_id:
          type: string
          docs: >-
            Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices
            to list all the available voices.
      display-name: Speech To Speech
      request:
        name: Body_Speech_to_Speech_v1_speech_to_speech__voice_id__post
        query-parameters:
          enable_logging:
            type: optional<boolean>
            default: true
            docs: >-
              When enable_logging is set to false zero retention mode will be
              used for the request. This will mean history features are
              unavailable for this request, including request stitching. Zero
              retention mode may only be used by enterprise customers.
          optimize_streaming_latency:
            type: optional<integer>
            docs: >
              You can turn on latency optimizations at some cost of quality. The
              best possible final latency varies by model. Possible values:

              0 - default mode (no latency optimizations)

              1 - normal latency optimizations (about 50% of possible latency
              improvement of option 3)

              2 - strong latency optimizations (about 75% of possible latency
              improvement of option 3)

              3 - max latency optimizations

              4 - max latency optimizations, but also with text normalizer
              turned off for even more latency savings (best latency, but can
              mispronounce eg numbers and dates).


              Defaults to None.
            availability: deprecated
          output_format:
            type: optional<root.OutputFormat>
            docs: The output format of the generated audio.
        body:
          properties:
            audio:
              type: file
              docs: >-
                The audio file which holds the content and emotion that will
                control the generated speech.
            model_id:
              type: optional<string>
              docs: >-
                Identifier of the model that will be used, you can query them
                using GET /v1/models. The model needs to have support for speech
                to speech, you can check this using the can_do_voice_conversion
                property.
              default: eleven_english_sts_v2
            voice_settings:
              type: optional<string>
              docs: >-
                Voice settings overriding stored settings for the given voice.
                They are applied only on the given request. Needs to be send as
                a JSON encoded string.
            seed:
              type: optional<integer>
              docs: >-
                If specified, our system will make a best effort to sample
                deterministically, such that repeated requests with the same
                seed and parameters should return the same result. Determinism
                is not guaranteed. Must be integer between 0 and 4294967295.
            remove_background_noise:
              type: optional<boolean>
              docs: >-
                If set, will remove the background noise from your audio input
                using our audio isolation model. Only applies to Voice Changer.
              default: false
            file_format:
              type: optional<SpeechToSpeechConvertRequestFileFormat>
              docs: >-
                The format of input audio. Options are 'pcm_s16le_16' or 'other'
                For `pcm_s16le_16`, the input audio must be 16-bit PCM at a
                16kHz sample rate, single channel (mono), and little-endian byte
                order. Latency will be lower than with passing an encoded
                waveform.
        content-type: multipart/form-data
      response:
        docs: The generated audio file
        type: file
        status-code: 200
      errors:
        - root.UnprocessableEntityError
      examples:
        - path-parameters:
            voice_id: JBFqnCBsd6RMkjVDRZzb
          query-parameters:
            output_format: mp3_44100_128
          request:
            model_id: eleven_multilingual_sts_v2
    convert_as_stream:
      path: /v1/speech-to-speech/{voice_id}/stream
      method: POST
      auth: false
      docs: >-
        Stream audio from one voice to another. Maintain full control over
        emotion, timing and delivery.
      source:
        openapi: ../openapi.json
      path-parameters:
        voice_id:
          type: string
          docs: >-
            Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices
            to list all the available voices.
      display-name: Speech To Speech Streaming
      request:
        name: >-
          Body_Speech_to_Speech_Streaming_v1_speech_to_speech__voice_id__stream_post
        query-parameters:
          enable_logging:
            type: optional<boolean>
            default: true
            docs: >-
              When enable_logging is set to false zero retention mode will be
              used for the request. This will mean history features are
              unavailable for this request, including request stitching. Zero
              retention mode may only be used by enterprise customers.
          optimize_streaming_latency:
            type: optional<integer>
            docs: >
              You can turn on latency optimizations at some cost of quality. The
              best possible final latency varies by model. Possible values:

              0 - default mode (no latency optimizations)

              1 - normal latency optimizations (about 50% of possible latency
              improvement of option 3)

              2 - strong latency optimizations (about 75% of possible latency
              improvement of option 3)

              3 - max latency optimizations

              4 - max latency optimizations, but also with text normalizer
              turned off for even more latency savings (best latency, but can
              mispronounce eg numbers and dates).


              Defaults to None.
            availability: deprecated
          output_format:
            type: optional<root.OutputFormat>
            docs: The output format of the generated audio.
        body:
          properties:
            audio:
              type: file
              docs: >-
                The audio file which holds the content and emotion that will
                control the generated speech.
            model_id:
              type: optional<string>
              docs: >-
                Identifier of the model that will be used, you can query them
                using GET /v1/models. The model needs to have support for speech
                to speech, you can check this using the can_do_voice_conversion
                property.
              default: eleven_english_sts_v2
            voice_settings:
              type: optional<string>
              docs: >-
                Voice settings overriding stored settings for the given voice.
                They are applied only on the given request. Needs to be send as
                a JSON encoded string.
            seed:
              type: optional<integer>
              docs: >-
                If specified, our system will make a best effort to sample
                deterministically, such that repeated requests with the same
                seed and parameters should return the same result. Determinism
                is not guaranteed. Must be integer between 0 and 4294967295.
            remove_background_noise:
              type: optional<boolean>
              docs: >-
                If set, will remove the background noise from your audio input
                using our audio isolation model. Only applies to Voice Changer.
              default: false
            file_format:
              type: optional<SpeechToSpeechConvertAsStreamRequestFileFormat>
              docs: >-
                The format of input audio. Options are 'pcm_s16le_16' or 'other'
                For `pcm_s16le_16`, the input audio must be 16-bit PCM at a
                16kHz sample rate, single channel (mono), and little-endian byte
                order. Latency will be lower than with passing an encoded
                waveform.
        content-type: multipart/form-data
      response:
        docs: Streaming audio data
        type: file
        status-code: 200
      errors:
        - root.UnprocessableEntityError
      examples:
        - path-parameters:
            voice_id: JBFqnCBsd6RMkjVDRZzb
          query-parameters:
            output_format: mp3_44100_128
          request:
            model_id: eleven_multilingual_sts_v2
  source:
    openapi: ../openapi.json
